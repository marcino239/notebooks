{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few packages which can help with implementation of RNNs and their need for high performance calculations.  I like caffe the most but it can be chalenging especially when it comes to adding new code as you need to deal with C++ and Cuda.  There is also Theano, but I am not a great fun with heavy computational tree optimisation especially during evaluation stage.  There is also Torch based on Lua which is ... well I don't know what Torch can do at this stage ...\n",
    "  \n",
    "Hence this post will be about implementing linear regression using Cuda Tensors and Torch 7.  The example is based on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'cutorch';\n",
    "require 'cunn';\n",
    "require 'optim';\n",
    "\n",
    "torch.setdefaulttensortype( 'torch.FloatTensor' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we will use fairly large table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_len = 1000000\n",
    "x_width = 2\n",
    "\n",
    "X = torch.CudaTensor( x_len, x_width ):normal()\n",
    "A = torch.CudaTensor{ {1}, {2} }\n",
    "Y = torch.mm( X, A ) + torch.CudaTensor( x_len, 1 ):normal( 3.0, 1.0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's define linear layer to express our regression.  NN package will take care of gradient derivation as well as forward and backward passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lin_layer = nn.Linear( (#X)[2], (#Y)[2] )\n",
    "model = nn.Sequential()\n",
    "model:add( lin_layer )\n",
    "model:cuda()\n",
    "criterion = nn.MSECriterion()\n",
    "criterion:cuda()\n",
    "params, dl_dparams = model:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_params = {\n",
    "    learningRate = 1e-3,\n",
    "    learningRateDecay = 1e-4,\n",
    "    weightDecay = 0,\n",
    "    momentum = 0\n",
    "}\n",
    "epochs = 100\n",
    "batch_size = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function train( X, Y )\n",
    "    \n",
    "    local current_loss = 0\n",
    "\n",
    "    -- for each mini batch\n",
    "    for t = 1,(#X)[1], batch_size do\n",
    "        -- prepare mini batch\n",
    "        local inputs = torch.CudaTensor( batch_size, x_width )\n",
    "        local targets = torch.CudaTensor( batch_size )\n",
    "\n",
    "        local i_start = 1\n",
    "        local i_end = batch_size\n",
    "        \n",
    "        local x_start = t\n",
    "        local x_end = math.min( t + batch_size - 1, (#X)[1] )\n",
    "        \n",
    "        inputs[ {{i_start, i_end}} ] = X[ {{x_start, x_end}} ]:clone()\n",
    "        targets[ {{i_start, i_end}} ] = Y[ {{x_start, x_end}} ]:clone()\n",
    "        \n",
    "        -- eval function to minimise \n",
    "        feval = function( params_new )\n",
    "            -- clean up \n",
    "            collectgarbage()\n",
    "\n",
    "            if params ~= params_new then\n",
    "                params:copy( params_new )\n",
    "            end\n",
    "\n",
    "            -- reset gradients (gradients are always accumulated, to accomodate batch methods)\n",
    "            dl_dparams:zero()\n",
    "\n",
    "            -- evaluate the loss function and its derivative wrt x, for that sample\n",
    "            local outputs = model:forward( inputs )\n",
    "            local loss = criterion:forward( outputs, targets )\n",
    "            local backprop = criterion:backward( outputs, targets )\n",
    "            model:backward( inputs, backprop )\n",
    "\n",
    "            -- return loss and dloss/dparams\n",
    "            return loss, dl_dparams\n",
    "        end\n",
    "\n",
    "        -- run SGD\n",
    "        _, fs = optim.sgd( feval, params, sgd_params )\n",
    "        current_loss = current_loss + fs[1]\n",
    "    end\n",
    "    \n",
    "    return current_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final loss = 2.0011432409287e-05\t\n",
       "Time per epoch = 37.918411016464[s]\t\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = sys.clock()\n",
    "local cumm_loss = 0.\n",
    "for i = 1, epochs do\n",
    "    cumm_loss = train( X, Y )\n",
    "--    io.write( '.' )\n",
    "end\n",
    "\n",
    "print( 'Final loss = ' .. cumm_loss / (#X)[1] )\n",
    "\n",
    "-- time taken\n",
    "time = sys.clock() - time\n",
    "print( \"Time per epoch = \" .. (time*1) .. '[s]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at recovered parameters.  They should be equal to:  \n",
    "```\n",
    "1  \n",
    "2  \n",
    "3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.9987\n",
       " 1.9987\n",
       " 2.9975\n",
       "[torch.CudaTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( params )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
